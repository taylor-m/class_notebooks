{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/AdamSpannbauer/c99c366b0c7d5b6c4920a46c32d738e5\n",
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read in and get to know the data.  We want to eventually predict `Profit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://docs.google.com/spreadsheets/d/1RJrLftlRnj6gmrYewqxykVKSyl7aV-Ktd3sUNQILidM/export?format=csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do we have an even distribution of states?  We'll eventually encode this variable to be numeric, how should we encode it? Which category would be the 'default'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a pair plot with all of the data, what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a train test split stratified by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One hot encode\n",
    "\n",
    "We'll take a look at using the `ColumnTransformer` today.  This is a way to write a 1 stop shop for all of your column preprocessing for a supervised learning model.  We can use it to one hot encode categorical variables and scale numeric variables all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which columns are cat and num\n",
    "# For one hot encoding, specify which categories to drop\n",
    "cat_cols = [\"State\"]\n",
    "drop_cats = [\"California\"]\n",
    "\n",
    "num_cols = [\"R&D Spend\", \"Administration\", \"Marketing Spend\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option showing how to onehotencode and leave numerics untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    #   Format\n",
    "    #   [(\"name of step\", WhatToDo(), list_of_columns_to_do_it_to)]\n",
    "    [(\"one_hot_encode\", OneHotEncoder(drop=drop_cats), cat_cols)],\n",
    "    # Do nothing to the rest of the data\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option showing how to onehotencode and scale numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct =ColumnTransformer(\n",
    "#     #   Format\n",
    "#     #   [(\"name of step\", WhatToDo(), list_of_columns_to_do_it_to)]\n",
    "#     [(\"one_hot_encode\", OneHotEncoder(drop=drop_cats), cat_cols)],\n",
    "#     # Scale the rest of the data\n",
    "#     remainder=StandardScaler(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big benefit of this is a single `fit` method that figures out how to one hot encode and scale and whatever else all at once.  We also have a single `transform` method that prepares all of our data at once.  This is a big big big plus for being able to predict on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit(X_train)\n",
    "\n",
    "X_train_trans = ct.transform(X_train)\n",
    "X_test_trans = ct.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_trans, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_trans, index=X_test.index)\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside to this is it's harder to trackdown the variable\n",
    "names :(\n",
    "\n",
    "If we don't care about interpretability (just focused\n",
    "on accuracy), this isn't terrible.  It's annoying if we care\n",
    "about interpreting, and with linear regression we almost always care about interpreting coefficients.\n",
    "\n",
    "This is admittedly, a pain.  Ugly code below to address the issue for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ct.transformers_[0][1].get_feature_names(cat_cols)\n",
    "cat_names = list(cat_names)\n",
    "\n",
    "new_col_names = cat_names + num_cols\n",
    "\n",
    "X_train.columns = new_col_names\n",
    "X_test.columns = new_col_names\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and drive home why this is better than `pd.get_dummies` in a machine learning context.  For our model's to make any difference to the business they need to be 'deployed'; that is, they need to be living somewhere that they can receive new data and make predictions.\n",
    "\n",
    "Let's say we run a website for people to judge how well a startup would do.  All users need to do is go to our website, fill out a form that asks them for the `'R&D Spend'`, `'Administration'`, `'Marketing Spend'`, and `'State'`.  Given this info, our model is expected to predict how much `'Profit'` we think the startup will have.\n",
    "\n",
    "^This means that we'll get one new observation at a time.  Below is an example of what a user might input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = pd.DataFrame(\n",
    "    {\n",
    "        \"R&D Spend\": [73721],\n",
    "        \"Administration\": [121344],\n",
    "        \"Marketing Spend\": [211025],\n",
    "        \"State\": [\"California\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "new_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For us to make a prediction, we need to reformat this data the same way we reformatted our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of what the training data looks like right now.\n",
    "# Our new observation needs to match for our model to know\n",
    "# what to do (column names optional, models dont care about them)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you'd think to use `pd.get_dummies()`. What's the issue with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the extra work we put into the `ColumnTransformer()` pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "* Check for multicollinearity with VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a model using statsmodels and display the summary\n",
    "    * Interpret $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the normality of residuals assumption with a qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check the homoscedasticity assumption with `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a plot of actuals vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate MAE, MAPE, MSE, & RMSE\n",
    "  * Interpret MAE and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "#### Group A: \n",
    "\n",
    "Re-fit the model, but use either `QuantileTransformer()`, `StandardScaler()`, or `MinMaxScaler()`.\n",
    "\n",
    "#### Group B:\n",
    "\n",
    "Re-fit the model, but drop the predictor that was the worst predictor in our original model.\n",
    "\n",
    "----\n",
    "\n",
    "* Using the `statsmodels` output as a reference: Is your model performing better, worse, or no different than our original model? Which numbers back this up?\n",
    "* Use `MAE` to evaluate your model.  Interpret this number for a business person.  According to this metric, how does your model perform compared to the original (again, express this as if you're talking to a business person)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write new code for this or modify the above existing code\n",
    "# Modifying is prolly less effort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `sklearn`'s `cross_val_score` to see a more 'stable' picture of your model's accuracy\n",
    "* Use `cross_val_score` to calculate $R^2$\n",
    "    * $R^2$ is the default score\n",
    "    * We can choose from [a long list of scores](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values) `sklearn` can do for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `cross_val_score` with a different score than $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
