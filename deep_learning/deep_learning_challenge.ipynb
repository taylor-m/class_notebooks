{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1e9a3f122dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "input_dim = 784 # 28*28 pixel grayscale images\n",
    "output_dim = nb_classes = 10 # 10 class labels in the dataset\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "# X_train reshape to 60k samples by 10 target classes\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "\n",
    "# X test set reshape to 10k samples by 10 target classes\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "\n",
    "# changing var types to 32bit floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# min max scaling of the train and test sets\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess your data so that you can feed it into ANN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split your data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Try different ANN models and train them on your training set. You can play with the following:\n",
    "    * Number of layers\n",
    "    * Activation functions of the layers\n",
    "    * Number of neurons in the layers\n",
    "    * Different batch sizes during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model A\n",
    "* hidden layers: 1\n",
    "* nodes: 1028, 1028, 10\n",
    "* activation : relu\n",
    "* batch size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d249b45f40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(1028, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# second dense layer, 1st hidden layer\n",
    "model.add(Dense(1028, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 87.68% accuracy\n",
    "* loss score: 0.3544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40327802300453186, 0.8582000136375427]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Model B\n",
    "* hidden layers: 2\n",
    "* nodes: 1028, 1028, 1028, 10\n",
    "* activation: relu\n",
    "* batch size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 1.3563 - accuracy: 0.6134 0s - loss: 1.3671 - accuracy\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.6123 - accuracy: 0.7986\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.5140 - accuracy: 0.8227\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.4833 - accuracy: 0.8330 0s - loss:\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4532 - accuracy: 0.8426\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.4383 - accuracy: 0.8467\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.4214 - accuracy: 0.8516\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.3993 - accuracy: 0.8615\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.4035 - accuracy: 0.8600\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.86 - 18s 39ms/step - loss: 0.3897 - accuracy: 0.8641\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.3811 - accuracy: 0.8675\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.3699 - accuracy: 0.8713\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.3710 - accuracy: 0.87140s - loss: 0.3711 - accuracy: \n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.3616 - accuracy: 0.8733\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.3569 - accuracy: 0.87350s - loss: 0.3570 - ac\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 14s 31ms/step - loss: 0.3535 - accuracy: 0.8771\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.3523 - accuracy: 0.8765\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.3386 - accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.3341 - accuracy: 0.8807\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.3250 - accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d237a23430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(1028, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# second dense layer, 1st hidden layer\n",
    "model.add(Dense(1028, activation='relu'))\n",
    "\n",
    "# third dense layer, 2nd hidden layer\n",
    "model.add(Dense(1028, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 88.48% accuracy\n",
    "* 0.3250 loss score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3736502230167389, 0.8687999844551086]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test score, test accuracy\n",
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare your models' training scores and interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate how your models perform on your test set. Compare the results of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
