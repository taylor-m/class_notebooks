{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned how to build linear regression models and interpret estimated coefficients. In this checkpoint, you'll explore how to evaluate model performance in the training phase. Recall that there are two contexts where performance matters: with the training set and with a test set. When you evaluate performance related to the training set, that enables you to talk about how well your model explains the information in the target variable. And evaluating a test set's performance tells you how well your model will perform when it's given previously unseen observations.\n",
    "\n",
    "In this checkpoint, you'll go over concepts like *F-tests* and *R-squared*. F-tests allow you to compare your model to a reduced model with no features. R-squared (and *adjusted R-squared*, which is a variant of R-squared) values tell you how well the model accounts for variance in the target.\n",
    "\n",
    "After that, you'll see how to compare different models in terms of their explanatory power. You'll learn how to read the *Akaike information criterion* and the *Bayesian information criterion* for this purpose.\n",
    "\n",
    "## Key topics\n",
    "\n",
    "* Training and test data\n",
    "* Evaluating training performance\n",
    "* F-tests\n",
    "* Degrees of freedom\n",
    "* R-squared\n",
    "* Akaike information criterion\n",
    "* Bayesian information criterion\n",
    "\n",
    "At the end of this checkpoint, you'll work through two assignments where you'll evaluate the performance of your weather and house prices models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is your model better than an \"empty\" model?\n",
    "\n",
    "When evaluating your model, you first need to ask whether your model contributes anything to the explanation of the outcome variable. In other words, you need to determine whether or not your features explain variance in the outcome. If they don't, you could drop your features altogether, and the resulting \"empty\" model would perform equally well—which is to say, not very well!\n",
    "\n",
    "For this purpose, use an *F-test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  F-tests\n",
    "\n",
    "F-tests can be calculated in different ways, depending on the situation. But in general, they represent the ratio between a model's unexplained variance compared to a reduced model. Here, the reduced model is a model with no features, meaning that all variance in the outcome is unexplained. For a linear regression model with two parameters $y=\\alpha+\\beta x$, the F-test is built from these pieces:\n",
    "\n",
    "| Name | Equation | \n",
    "| :-- | :-- |\n",
    "| Unexplained model variance | $$SSE_F=\\sum(y_i-\\hat{y}_i)^2$$ |\n",
    "| Unexplained variance in reduced model | $$SSE_R=Var_y = \\sum(y_i-\\bar{y})^2$$ |\n",
    "| Number of parameters in the model | $$p_F = 2 (\\alpha \\text{ and } \\beta)$$ |\n",
    "| Number of parameters in the reduced model | $$p_R = 1 (\\alpha)$$ |\n",
    "| Number of observations | $$n$$ |\n",
    "| Degrees of freedom of $SSE_F$ | $$df_F = n - p_F$$ |\n",
    "| Degrees of freedom of $SSE_R$ | $$df_R = n - p_R$$ |\n",
    "\n",
    "These pieces come together to give you the full equation for the F-test:\n",
    "\n",
    "$$F=\\dfrac{SSE_F-SSE_R}{df_F-df_R}÷\\dfrac{SSE_F}{df_F}$$\n",
    "\n",
    "This introduces some new terminology. *Degrees of freedom* quantifies the amount of information \"left over\" to estimate variability after all parameters are estimated.\n",
    "\n",
    "In regression, degrees of freedom for a function works like this: With two data points, a regression line $y=\\alpha + \\beta x$ has `0` degrees of freedom (`2` minus the number of parameters). Those two parameters encompass all the information in the data. Knowing $\\alpha$ and $\\beta$ alone, you can perfectly reproduce the original data. No additional information is available from the data itself. If you have 10 data points, then the model's degrees of freedom would be `8` (`10` minus the number of parameters).\n",
    "\n",
    "The F-test's null hypothesis states that the model is indistinguishable from the reduced model, which means that the features contribute nothing to the explanation of the target variable. Instead of reading the F-statistic, it's easier to read its associated p-value. The lower the p-value, the better your model. Namely, if the p-value of the F-test for your model is less than or equal to `0.1` (or even less than or equal to `0.05`), you can say that your model is useful and contributes something that is statistically significant in the explanation of the target.\n",
    "\n",
    "Now, calculate the F-statistic of your medical costs model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Display preferences\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>25.740</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3756.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>33.440</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>8240.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>27.740</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>7281.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>29.830</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>6406.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>25.840</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>28923.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     region   charges\n",
       "0   19  female 27.900         0    yes  southwest 16884.900\n",
       "1   18    male 33.770         1     no  southeast  1725.550\n",
       "2   28    male 33.000         3     no  southeast  4449.460\n",
       "3   33    male 22.705         0     no  northwest 21984.500\n",
       "4   32    male 28.880         0     no  northwest  3866.860\n",
       "5   31  female 25.740         0     no  southeast  3756.620\n",
       "6   46  female 33.440         1     no  southeast  8240.590\n",
       "7   37  female 27.740         3     no  northwest  7281.510\n",
       "8   37    male 29.830         2     no  northeast  6406.410\n",
       "9   60  female 25.840         0     no  northwest 28923.100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'medicalcosts'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "insurance_df = pd.read_sql_query('select * from medicalcosts',con=engine)\n",
    "\n",
    "# No need for an open connection, because you're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "insurance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     986.5\n",
      "Date:                Wed, 19 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:18:48   Log-Likelihood:                -13557.\n",
      "No. Observations:                1338   AIC:                         2.712e+04\n",
      "Df Residuals:                    1333   BIC:                         2.715e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.163e+04    947.267    -12.281      0.000   -1.35e+04   -9775.195\n",
      "is_male     -109.0414    334.665     -0.326      0.745    -765.568     547.486\n",
      "is_smoker   2.383e+04    414.187     57.544      0.000     2.3e+04    2.46e+04\n",
      "age          259.4531     11.942     21.727      0.000     236.027     282.880\n",
      "bmi          323.0510     27.529     11.735      0.000     269.046     377.056\n",
      "==============================================================================\n",
      "Omnibus:                      299.394   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              708.640\n",
      "Skew:                           1.212   Prob(JB):                    1.32e-154\n",
      "Kurtosis:                       5.614   Cond. No.                         292.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "insurance_df[\"is_male\"] = pd.get_dummies(insurance_df.sex, drop_first=True)\n",
    "insurance_df[\"is_smoker\"] = pd.get_dummies(insurance_df.smoker, drop_first=True)\n",
    "\n",
    "# `Y` is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# `X` is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi']]\n",
    "\n",
    "# Add a constant to the model because it's best practice\n",
    "# to do so every time!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's F-statistic is `986.5`, and the associated p-value is very close to zero. This means that your features add some information to the reduced model, and your model is useful in explaining `charges`.\n",
    "\n",
    "However, F-tests don't quantify how much information your model contributes. That requires R-squared, which you'll learn about next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying a model's performance on the training set\n",
    "\n",
    "R-squared is probably the most common measure of goodness of fit in a linear regression model. It is a proportion (between `0` and `1`) that expresses how much variance in the outcome variable is explained by the explanatory variables in the model. Generally speaking, higher $R^2$ values are better to a point. A low $R^2$ indicates that your model isn't explaining much information about the outcome, which means that it will not give very good predictions. But a very high $R^2$ is a warning sign of overfitting. No dataset is a perfect representation of reality, so a model that perfectly fits your data ($R^2$ of `1` or close to `1`) is likely to be biased by quirks in the data and will perform less well on the test set.\n",
    "\n",
    "In the regression summary table above, you can see that your medical costs model's R-squared value is `0.747`. This means that your model explains 74.7% of the variance in the charges, leaving 25.3% unexplained. You can conclude that there's still room for improvement. Now, fit the model in the previous checkpoint again, where you included the interaction of `BMI` and the `is_smoking` dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     1365.\n",
      "Date:                Wed, 19 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:18:50   Log-Likelihood:                -13265.\n",
      "No. Observations:                1338   AIC:                         2.654e+04\n",
      "Df Residuals:                    1332   BIC:                         2.657e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2071.0750    840.644     -2.464      0.014   -3720.206    -421.944\n",
      "is_male        -473.4954    269.612     -1.756      0.079   -1002.406      55.415\n",
      "is_smoker     -2.019e+04   1666.492    -12.117      0.000   -2.35e+04   -1.69e+04\n",
      "age             266.3723      9.612     27.713      0.000     247.516     285.228\n",
      "bmi               7.9686     25.044      0.318      0.750     -41.160      57.098\n",
      "bmi_is_smoker  1435.6081     53.242     26.964      0.000    1331.160    1540.056\n",
      "==============================================================================\n",
      "Omnibus:                      710.004   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4260.532\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.183   Cond. No.                         661.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# `Y` is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# This is the interaction between BMI and smoking\n",
    "insurance_df[\"bmi_is_smoker\"] = insurance_df.bmi * insurance_df.is_smoker\n",
    "\n",
    "# `X` is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi', \"bmi_is_smoker\"]]\n",
    "\n",
    "# Add a constant to the model because it's best practice\n",
    "# to do so every time!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared of this model is `0.837`, which is higher than your previous model's R-squared. This improvement indicates that the interaction of `BMI` and `is_smoker` explains some previously unexplained variance in `charges`. \n",
    "\n",
    "As mentioned before, high R-squared values are generally desirable. But, in some cases, very high R-squared values indicate some potential problems with a model. Specifically, it could mean the following:\n",
    "\n",
    "* A very high R-squared value may be a sign of overfitting. If your model is too complex for the data, then it may overfit the training set and do a poor job on the test set. That said, there isn't an agreed-upon R-squared threshold to detect overfitting. Instead, you need to compare the model's performance on test versus training data. If your model performs significantly worse on the test set than the training set, you should suspect overfitting. You'll explore how to evaluate linear regression models on the test set in the next checkpoint.\n",
    "\n",
    "* R-squared is an inherently biased estimate of the performance, in the sense that the more explanatory variables are added to the model, the higher R-squared values you get. This is true even when you include irrelevant variables like noises or random data. To mitigate this problem, data scientists usually use a metric called *adjusted R-squared* instead of *R-squared*. Adjusted R-squared does the same job as R-squared, but it is adjusted according to the number of features included in the model. Hence, it's always safer to look at the adjusted R-squared value instead of R-squared value.\n",
    "\n",
    "**A note on negative R-squared values:** It is possible to get negative R-squared values for some models. In general, if a model is weaker than a straight horizontal line, then the R-squared value becomes negative. This usually happens when a constant is not included in the model. If you get a negative value for R-squared, that means that your model explains the target very poorly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different models\n",
    "\n",
    "Comparing different models and choosing the best one is an essential practice in data science. Often, you'll try several models and evaluate their performance on a test set in order to determine the top-performing model. However, *inference* is also a critical task when it comes to linear regression models. Unlike testing the predictive power, in inference, you care about the explanatory power of your models.\n",
    "\n",
    "Throughout this checkpoint, you've seen that you can measure the performance of your models on the training set using F-test or R-squared. Hence, both F-test and R-squared can be used to compare different models. Unfortunately, the two metrics suffer from some drawbacks that make them inappropriate to use in certain situations.\n",
    "\n",
    "Here, you'll briefly explore how you can use F-tests and R-squared to compare models. Then, you'll learn about information criteria that you can also use to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using F-tests for model comparison\n",
    "\n",
    "You can use an F-test to compare two models if one of them is nested within the other. That is, if the feature set in a model is a subset of the feature set of the other, then you can use an F-test. In this case, you say that the model with the higher F-statistic is superior to the other model.\n",
    "\n",
    "However, if models are not nested, then using an F-test may be misleading. F-tests are quite sensitive to the normality of the error terms. If errors are not normally distributed, you should try other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using R-squared for model comparison\n",
    "\n",
    "R-squared can also be used. You already saw that R-squared is biased, as it tends to increase with the number of explanatory variables. So, instead of R-squared, you can use adjusted R-squared. The higher the adjusted R-squared, the better the model explains the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using information criteria\n",
    "\n",
    "Using information criteria is also a common way of comparing different models and selecting the best one. Here, you'll learn about two information criteria: *Akaike information criterion* (AIC) and *Bayesian information criterion* (BIC). Both take into consideration the sum of the squared errors (SSE), the sample size, and the number of parameters.\n",
    "\n",
    "The formula for AIC is as follows:\n",
    "\n",
    "$$nln(SSE)−nln(n)+2p$$ \n",
    "\n",
    "\n",
    "And the formula for BIC is as follows:\n",
    "\n",
    "$$nln(SSE)−nln(n)+pln(n)$$\n",
    "\n",
    "In both of these formulas, $n$ represents the sample size, $p$ represents the number of regression coefficients in the model (including the constant), and $ln$ stands for the natural logarithm.\n",
    "\n",
    "For both AIC and BIC, lower values indicate better models. So you should choose the model with the lowest AIC or BIC value. Although you can use either of the two criteria, AIC is often criticized for its tendency to overfit. In contrast, BIC penalizes the number of parameters more severely than AIC, so it favors more parsimonious models (that is, models with fewer parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which medical costs model is better?\n",
    "\n",
    "The statmodels' `summary()` function provides all of the above metrics. Take a look at these metrics in the tables above. For your first model, R-squared is `0.747`, adjusted R-squared is `0.747`, the F-statistic is `986.5`, AIC is `27.120`, and BIC is `27.150`. For your second model, R-squared is `0.837`, adjusted R-squared is `0.836`, the F-statistic is `1365`, AIC is `26.540`, and BIC is `26.570`. According to all of the metrics, the second model seems better than the first one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
