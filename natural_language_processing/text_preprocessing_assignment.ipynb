{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_preprocessing_assignment.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"222px"},"toc_section_display":true,"toc_window_display":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"-v_F8U7U_2_i"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"MWAXIhb0_2_k"},"source":["# %reload_ext nb_black\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","from scipy import stats\n","\n","plt.style.use([\"dark_background\"])\n","from collections import Counter\n","import nltk\n","import spacy\n","import re\n","import multiprocessing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"2AXpdrvS_2_k","executionInfo":{"status":"ok","timestamp":1613667124708,"user_tz":360,"elapsed":5622,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"8889228b-9911-453f-ff97-aa6c087b141e"},"source":["# twitter us airline sentiment data\n","postgres_user = \"dsbc_student\"\n","postgres_pw = \"7*.8G9QH21\"\n","postgres_host = \"142.93.121.174\"\n","postgres_port = \"5432\"\n","postgres_db = \"twitter_sentiment\"\n","conn_str = f\"postgresql://{postgres_user}:{postgres_pw}@{postgres_host}:{postgres_port}/{postgres_db}\"\n","query = \"\"\"\n","SELECT *\n","FROM twitter\n","\"\"\"\n","twitter = pd.read_sql_query(query, con=conn_str, index_col=\"index\")\n","twitter.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n","  \"\"\")\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>airline_sentiment</th>\n","      <th>airline_sentiment_confidence</th>\n","      <th>negativereason</th>\n","      <th>negativereason_confidence</th>\n","      <th>airline</th>\n","      <th>airline_sentiment_gold</th>\n","      <th>name</th>\n","      <th>negativereason_gold</th>\n","      <th>retweet_count</th>\n","      <th>text</th>\n","      <th>tweet_coord</th>\n","      <th>tweet_created</th>\n","      <th>tweet_location</th>\n","      <th>user_timezone</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>570306133677760513</td>\n","      <td>neutral</td>\n","      <td>1.0000</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>None</td>\n","      <td>cairdin</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>@VirginAmerica What @dhepburn said.</td>\n","      <td>None</td>\n","      <td>2015-02-24 11:35:52 -0800</td>\n","      <td>None</td>\n","      <td>Eastern Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>570301130888122368</td>\n","      <td>positive</td>\n","      <td>0.3486</td>\n","      <td>None</td>\n","      <td>0.0000</td>\n","      <td>Virgin America</td>\n","      <td>None</td>\n","      <td>jnardino</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>@VirginAmerica plus you've added commercials t...</td>\n","      <td>None</td>\n","      <td>2015-02-24 11:15:59 -0800</td>\n","      <td>None</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>570301083672813571</td>\n","      <td>neutral</td>\n","      <td>0.6837</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>None</td>\n","      <td>yvonnalynn</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n","      <td>None</td>\n","      <td>2015-02-24 11:15:48 -0800</td>\n","      <td>Lets Play</td>\n","      <td>Central Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>570301031407624196</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Bad Flight</td>\n","      <td>0.7033</td>\n","      <td>Virgin America</td>\n","      <td>None</td>\n","      <td>jnardino</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>@VirginAmerica it's really aggressive to blast...</td>\n","      <td>None</td>\n","      <td>2015-02-24 11:15:36 -0800</td>\n","      <td>None</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>570300817074462722</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Can't Tell</td>\n","      <td>1.0000</td>\n","      <td>Virgin America</td>\n","      <td>None</td>\n","      <td>jnardino</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>@VirginAmerica and it's a really big bad thing...</td>\n","      <td>None</td>\n","      <td>2015-02-24 11:14:45 -0800</td>\n","      <td>None</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 tweet_id  ...               user_timezone\n","index                      ...                            \n","0      570306133677760513  ...  Eastern Time (US & Canada)\n","1      570301130888122368  ...  Pacific Time (US & Canada)\n","2      570301083672813571  ...  Central Time (US & Canada)\n","3      570301031407624196  ...  Pacific Time (US & Canada)\n","4      570300817074462722  ...  Pacific Time (US & Canada)\n","\n","[5 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"_ZcD4lH6_2_l"},"source":["---\n","# Tokenization"]},{"cell_type":"code","metadata":{"id":"voXFUje6_2_l"},"source":["# tweets Tokenization\n","nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n","# nlp.create_pipe(\"sentencizer\")\n","# nlp.add_pipe(\"sentencizer\")\n","nlp.max_length = 20000000\n","\n","airlines_string = \" \".join(twitter.text)\n","\n","\n","tweets = nlp(airlines_string)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Fqv8Htu_2_l"},"source":["---\n","# Removing Stop Words"]},{"cell_type":"code","metadata":{"id":"EqRU-v0-_2_m"},"source":["# dialogs_no_stop_words = [token for token in dialogs if not token.is_stop]\n","\n","tweets_no_stop_words = [token for token in tweets if not token.is_stop]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQThiGMx_2_m"},"source":["# Utility function to calculate how frequently words appear in the text\n","def word_frequencies(text):\n","    \n","    # Build a list of words\n","    # Strip out punctuation\n","    words = []\n","    for token in text:\n","        if not token.is_punct:\n","            words.append(token.text)\n","            \n","    # Build and return a `Counter` object containing word counts\n","    return Counter(words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luDnyTl3_2_m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613667137234,"user_tz":360,"elapsed":18139,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"bf3d56c9-21c0-4371-e9bc-7c83956bc080"},"source":["# dialogs_word_freq = word_frequencies(dialogs_no_stop_words).most_common(25)\n","# print(\"\\ndialogs word frequencies: \", dialogs_word_freq)\n","tweets_word_freq = word_frequencies(tweets_no_stop_words).most_common(25)\n","print(\"\\ntweets wor frequencies: \", tweets_word_freq)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","tweets wor frequencies:  [('@united', 3733), ('flight', 3178), ('@AmericanAir', 2904), ('@USAirways', 2893), ('@SouthwestAir', 2390), ('@JetBlue', 2176), (' ', 1951), ('Cancelled', 1065), ('service', 928), ('time', 770), ('Flight', 740), ('help', 731), ('customer', 702), ('2', 663), ('hours', 653), ('amp', 636), ('hold', 635), ('flights', 614), ('plane', 612), ('thanks', 536), ('Thanks', 535), ('delayed', 505), ('Flightled', 505), ('@VirginAmerica', 493), ('gate', 475)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dVbgXiaM_2_m"},"source":["---\n","# Lemmatization"]},{"cell_type":"code","metadata":{"id":"o0Mr92rV_2_n"},"source":["# Utility function to calculate how frequently each lemma appears in the text\n","def lemma_frequencies(text):\n","    \n","    # Build a list of lemmas\n","    # Strip out punctuation\n","    lemmas = []\n","    for token in text:\n","        if not token.is_punct:\n","            lemmas.append(token.lemma_)\n","            \n","    # Build and return a `Counter` object containing lemma counts\n","    return Counter(lemmas)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apUCCGk6_2_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613667185802,"user_tz":360,"elapsed":484,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"13bc08a1-8d44-4967-97a0-722820ccddc0"},"source":["# dialog_lemmas = lemma_frequencies(dialogs_no_stop_words).most_common(25)\n","twitter_lemmas = lemma_frequencies(tweets_no_stop_words).most_common(25)\n","\n","# print(\"dialog lemmas: \", dialog_lemmas)\n","print(\"twitter lemmas: \", twitter_lemmas)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["twitter lemmas:  [('flight', 4006), ('@unite', 2712), ('@usairways', 2616), (' ', 1951), ('@JetBlue', 1740), ('thank', 1654), ('@AmericanAir', 1489), ('@americanair', 1450), ('@southwestair', 1280), ('@SouthwestAir', 1157), ('hour', 1126), ('@united', 1078), ('cancel', 973), ('delay', 970), ('service', 966), ('time', 958), ('customer', 914), ('help', 911), ('fly', 750), ('bag', 746), ('get', 745), ('wait', 739), ('plane', 723), ('hold', 712), ('need', 682)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"trW2oNCS_2_n"},"source":["# Sentences"]},{"cell_type":"code","metadata":{"id":"N2Ydu95o_2_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613667185802,"user_tz":360,"elapsed":478,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"310f60b5-3708-4dbf-d472-7f3dfb2a9fe9"},"source":["# dialog_sents = [dialogs.sents]\n","twitter_sents = [tweets.sents]\n","\n","# print(f\"There are {len(dialog_sents)} dialog sentences.\")\n","print(f\"There are {len(twitter_sents)} twitter sentences.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 twitter sentences.\n"],"name":"stdout"}]}]}