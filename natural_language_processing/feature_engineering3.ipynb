{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"feature_engineering3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbZiX7c2xxINBFdiPYuCEl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yEt3zox7qxQf"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"anx4TIuIrsFF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613695630012,"user_tz":360,"elapsed":12710,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"6ea072ca-06b3-4bbb-db78-8961393541e0"},"source":["import numpy as np\r\n","import pandas as pd\r\n","import sklearn\r\n","import spacy\r\n","import re\r\n","import nltk\r\n","from nltk.corpus import gutenberg\r\n","import gensim\r\n","import warnings\r\n","warnings.filterwarnings(\"ignore\")\r\n","\r\n","nltk.download('gutenberg')\r\n","!python -m spacy download en"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oF1lRrKtsMaH","executionInfo":{"status":"ok","timestamp":1613695630014,"user_tz":360,"elapsed":12707,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Utility function for standard text cleaning\r\n","def text_cleaner(text):\r\n","    # Visual inspection identifies a form of punctuation that spaCy doesn't\r\n","    # recognize: the double dash --. Better get rid of it now!\r\n","    text = re.sub(r'--',' ',text)\r\n","    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\r\n","    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\r\n","    text = ' '.join(text.split())\r\n","    return text"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sy0ZfzOBrp7D"},"source":["# Assignment\r\n","Train your own word2vec representations, as you did in the first example in this checkpoint. However, you need to experiment with the hyperparameters of the vectorization step. Modify the hyperparameters and run the classification models again. Can you wrangle any improvements?"]},{"cell_type":"code","metadata":{"id":"Dv2IIrRir1r2","executionInfo":{"status":"ok","timestamp":1613695630015,"user_tz":360,"elapsed":12705,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Load and clean the data\r\n","persuasion = gutenberg.raw('austen-persuasion.txt')\r\n","alice = gutenberg.raw('carroll-alice.txt')\r\n","\r\n","# The chapter indicator is idiosyncratic\r\n","persuasion = re.sub(r'Chapter \\d+', '', persuasion)\r\n","alice = re.sub(r'CHAPTER .*', '', alice)\r\n","    \r\n","alice = text_cleaner(alice)\r\n","persuasion = text_cleaner(persuasion)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XKnlEDfwRPC","executionInfo":{"status":"ok","timestamp":1613695680659,"user_tz":360,"elapsed":52456,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Parse the cleaned novels. This can take some time.\r\n","nlp = spacy.load('en')\r\n","alice_doc = nlp(alice)\r\n","persuasion_doc = nlp(persuasion)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"2CsebmGvwVCE","executionInfo":{"status":"ok","timestamp":1613695680669,"user_tz":360,"elapsed":41542,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"cd7a8a81-3d0f-4c7b-dad6-a393cf1a2051"},"source":["# Group into sentences\r\n","alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\r\n","persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\r\n","\r\n","# Combine the sentences from the two novels into one DataFrame\r\n","sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\r\n","sentences.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(So, she, was, considering, in, her, own, mind...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(Oh, dear, !)</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(I, shall, be, late, !, ')</td>\n","      <td>Carroll</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text   author\n","0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n","1  (So, she, was, considering, in, her, own, mind...  Carroll\n","2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n","3                                      (Oh, dear, !)  Carroll\n","4                         (I, shall, be, late, !, ')  Carroll"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6Ha8J1SDwcJG","executionInfo":{"status":"ok","timestamp":1613695681547,"user_tz":360,"elapsed":14534,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Get rid of stop words and punctuation,\r\n","# and lemmatize the tokens\r\n","for i, sentence in enumerate(sentences[\"text\"]):\r\n","    sentences.loc[i, \"text\"] = [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmYmzcspzoA_"},"source":["# Vectorization"]},{"cell_type":"code","metadata":{"id":"QyWkzvPkwkiK","executionInfo":{"status":"ok","timestamp":1613696934105,"user_tz":360,"elapsed":2540,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Train word2vec on the sentences\r\n","model = gensim.models.Word2Vec(\r\n","    sentences[\"text\"],\r\n","    workers=4,\r\n","    min_count=1,\r\n","    window=6,\r\n","    sg=0,\r\n","    sample=1e-3,\r\n","    size=100,\r\n","    hs=1\r\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6yp1k7Bw1bv","executionInfo":{"status":"ok","timestamp":1613696934106,"user_tz":360,"elapsed":1224,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"6c41425d-8869-4e02-c204-648748c536fb"},"source":["print(model.most_similar(positive=['lady', 'man'], negative=['woman'], topn=5))\r\n","print(model.doesnt_match(\"dad dinner mom aunt uncle\".split()))\r\n","print(model.similarity('woman', 'man'))\r\n","print(model.similarity('horse', 'cat'))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[('hour', 0.9991674423217773), ('come', 0.998889684677124), ('sea', 0.9988483190536499), ('garden', 0.9988287687301636), ('Cottage', 0.9987945556640625)]\n","aunt\n","0.9983593\n","0.9950253\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w9bVaDyb1MST","executionInfo":{"status":"ok","timestamp":1613696990523,"user_tz":360,"elapsed":2469,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Train word2vec on the sentences\r\n","model = gensim.models.Word2Vec(\r\n","    sentences[\"text\"],\r\n","    workers=4,\r\n","    min_count=1,\r\n","    window=8,\r\n","    sg=0,\r\n","    sample=1e-3,\r\n","    size=100,\r\n","    hs=1\r\n",")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkOv2gmv1OO-","executionInfo":{"status":"ok","timestamp":1613696990524,"user_tz":360,"elapsed":1219,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"163b09a7-7723-4ab3-8f3f-9ba95ae72c4c"},"source":["print(model.most_similar(positive=['lady', 'man'], negative=['woman'], topn=5))\r\n","print(model.doesnt_match(\"dad dinner mom aunt uncle\".split()))\r\n","print(model.similarity('woman', 'man'))\r\n","print(model.similarity('horse', 'cat'))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[('party', 0.9991901516914368), ('stand', 0.9991484880447388), ('early', 0.9989441633224487), ('horse', 0.9988605976104736), ('interesting', 0.9987533092498779)]\n","aunt\n","0.9954394\n","0.98536915\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V6fcOOPL1Zpb","executionInfo":{"status":"ok","timestamp":1613697003633,"user_tz":360,"elapsed":2722,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Train word2vec on the sentences\r\n","model = gensim.models.Word2Vec(\r\n","    sentences[\"text\"],\r\n","    workers=4,\r\n","    min_count=1,\r\n","    window=6,\r\n","    sg=0,\r\n","    sample=1e-2,\r\n","    size=100,\r\n","    hs=1\r\n",")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4x9dJSw91bpD","executionInfo":{"status":"ok","timestamp":1613697003635,"user_tz":360,"elapsed":1630,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"56c67e73-c309-48c7-ef20-bb6d747b93f1"},"source":["print(model.most_similar(positive=['lady', 'man'], negative=['woman'], topn=5))\r\n","print(model.doesnt_match(\"dad dinner mom aunt uncle\".split()))\r\n","print(model.similarity('woman', 'man'))\r\n","print(model.similarity('horse', 'cat'))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[('probably', 0.995675265789032), ('take', 0.9947940707206726), ('style', 0.9947859048843384), ('sneeze', 0.993588387966156), ('party', 0.9935703277587891)]\n","uncle\n","0.99427783\n","0.930716\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"izK1F0fC1mGC","executionInfo":{"status":"ok","timestamp":1613697035613,"user_tz":360,"elapsed":2324,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Train word2vec on the sentences\r\n","model = gensim.models.Word2Vec(\r\n","    sentences[\"text\"],\r\n","    workers=4,\r\n","    min_count=1,\r\n","    window=6,\r\n","    sg=0,\r\n","    sample=1e-4,\r\n","    size=100,\r\n","    hs=1\r\n",")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N85fqNae1l3S","executionInfo":{"status":"ok","timestamp":1613697036288,"user_tz":360,"elapsed":645,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"09e0927c-c0fc-4412-a5b7-9a574f39409f"},"source":["print(model.most_similar(positive=['lady', 'man'], negative=['woman'], topn=5))\r\n","print(model.doesnt_match(\"dad dinner mom aunt uncle\".split()))\r\n","print(model.similarity('woman', 'man'))\r\n","print(model.similarity('horse', 'cat'))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[('room', 0.9975862503051758), ('old', 0.9975762367248535), ('find', 0.9974665641784668), ('house', 0.9974289536476135), ('consequence', 0.9974139928817749)]\n","uncle\n","0.9982257\n","0.99333894\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ILWhIEJe1wPw","executionInfo":{"status":"ok","timestamp":1613697228126,"user_tz":360,"elapsed":2456,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Train word2vec on the sentences\r\n","model = gensim.models.Word2Vec(\r\n","    sentences[\"text\"],\r\n","    workers=4,\r\n","    min_count=1,\r\n","    window=5,\r\n","    sg=0,\r\n","    sample=1e-3,\r\n","    size=100,\r\n","    hs=1\r\n",")"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mU3cbJuo1wFT","executionInfo":{"status":"ok","timestamp":1613697228127,"user_tz":360,"elapsed":1633,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"e3d64a56-3bad-467d-a461-4685695e61e0"},"source":["print(model.most_similar(positive=['lady', 'man'], negative=['woman'], topn=5))\r\n","print(model.doesnt_match(\"dad dinner mom aunt uncle\".split()))\r\n","print(model.similarity('woman', 'man'))\r\n","print(model.similarity('horse', 'cat'))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[('large', 0.999431312084198), ('wife', 0.9989168643951416), ('spirit', 0.9987666606903076), ('warm', 0.9987398982048035), ('comfort', 0.9986565709114075)]\n","aunt\n","0.99716294\n","0.9954219\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440},"id":"GcKQIdaBy9pA","executionInfo":{"status":"ok","timestamp":1613697233999,"user_tz":360,"elapsed":950,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"aec57d33-9497-4d2a-ccc7-52ea34788569"},"source":["word2vec_arr = np.zeros((sentences.shape[0],100))\r\n","\r\n","for i, sentence in enumerate(sentences[\"text\"]):\r\n","    word2vec_arr[i,:] = np.mean([model[lemma] for lemma in sentence], axis=0)\r\n","\r\n","word2vec_arr = pd.DataFrame(word2vec_arr)\r\n","sentences = pd.concat([sentences[[\"author\", \"text\"]],word2vec_arr], axis=1)\r\n","sentences.dropna(inplace=True)\r\n","\r\n","sentences.head()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>text</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>...</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","      <th>70</th>\n","      <th>71</th>\n","      <th>72</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Carroll</td>\n","      <td>[Alice, begin, tired, sit, sister, bank, have,...</td>\n","      <td>0.048000</td>\n","      <td>-0.187704</td>\n","      <td>0.347052</td>\n","      <td>0.352550</td>\n","      <td>-0.101329</td>\n","      <td>-0.119254</td>\n","      <td>-0.260452</td>\n","      <td>0.366433</td>\n","      <td>0.262457</td>\n","      <td>0.597434</td>\n","      <td>-0.048809</td>\n","      <td>0.025462</td>\n","      <td>-0.262537</td>\n","      <td>0.414285</td>\n","      <td>-0.016715</td>\n","      <td>0.266028</td>\n","      <td>0.130056</td>\n","      <td>-0.091480</td>\n","      <td>0.087965</td>\n","      <td>-0.148100</td>\n","      <td>-0.028312</td>\n","      <td>0.002004</td>\n","      <td>-0.197226</td>\n","      <td>0.169833</td>\n","      <td>0.237772</td>\n","      <td>0.084147</td>\n","      <td>-0.330879</td>\n","      <td>-0.018147</td>\n","      <td>-0.046863</td>\n","      <td>0.180527</td>\n","      <td>-0.012896</td>\n","      <td>-0.050256</td>\n","      <td>0.004300</td>\n","      <td>-0.159269</td>\n","      <td>0.237287</td>\n","      <td>0.092049</td>\n","      <td>-0.205038</td>\n","      <td>-0.093129</td>\n","      <td>...</td>\n","      <td>-0.257731</td>\n","      <td>0.171465</td>\n","      <td>-0.302378</td>\n","      <td>-0.324319</td>\n","      <td>-0.199457</td>\n","      <td>-0.120065</td>\n","      <td>-0.028214</td>\n","      <td>-0.052656</td>\n","      <td>0.157933</td>\n","      <td>0.520118</td>\n","      <td>0.116002</td>\n","      <td>0.046345</td>\n","      <td>-0.012452</td>\n","      <td>-0.032985</td>\n","      <td>-0.047465</td>\n","      <td>-0.020088</td>\n","      <td>0.004033</td>\n","      <td>0.270443</td>\n","      <td>-0.377954</td>\n","      <td>0.369348</td>\n","      <td>-0.066029</td>\n","      <td>0.063120</td>\n","      <td>-0.414351</td>\n","      <td>0.420770</td>\n","      <td>-0.372577</td>\n","      <td>-0.217826</td>\n","      <td>0.296333</td>\n","      <td>-0.035934</td>\n","      <td>0.018498</td>\n","      <td>0.005265</td>\n","      <td>-0.028593</td>\n","      <td>-0.032186</td>\n","      <td>0.217536</td>\n","      <td>0.100305</td>\n","      <td>0.234729</td>\n","      <td>-0.098482</td>\n","      <td>-0.264533</td>\n","      <td>0.072370</td>\n","      <td>0.297547</td>\n","      <td>-0.019668</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Carroll</td>\n","      <td>[consider, mind, hot, day, feel, sleepy, stupi...</td>\n","      <td>0.028637</td>\n","      <td>-0.143616</td>\n","      <td>0.278461</td>\n","      <td>0.277434</td>\n","      <td>-0.077205</td>\n","      <td>-0.094961</td>\n","      <td>-0.203207</td>\n","      <td>0.295077</td>\n","      <td>0.206409</td>\n","      <td>0.476060</td>\n","      <td>-0.042261</td>\n","      <td>0.017701</td>\n","      <td>-0.208692</td>\n","      <td>0.334784</td>\n","      <td>-0.003024</td>\n","      <td>0.210780</td>\n","      <td>0.105593</td>\n","      <td>-0.072175</td>\n","      <td>0.070914</td>\n","      <td>-0.118777</td>\n","      <td>-0.032873</td>\n","      <td>-0.001665</td>\n","      <td>-0.165321</td>\n","      <td>0.135812</td>\n","      <td>0.198908</td>\n","      <td>0.067158</td>\n","      <td>-0.269467</td>\n","      <td>-0.017260</td>\n","      <td>-0.035316</td>\n","      <td>0.136428</td>\n","      <td>-0.004193</td>\n","      <td>-0.034832</td>\n","      <td>0.003719</td>\n","      <td>-0.123044</td>\n","      <td>0.186484</td>\n","      <td>0.076487</td>\n","      <td>-0.163870</td>\n","      <td>-0.072490</td>\n","      <td>...</td>\n","      <td>-0.201265</td>\n","      <td>0.132001</td>\n","      <td>-0.241908</td>\n","      <td>-0.258963</td>\n","      <td>-0.157889</td>\n","      <td>-0.096313</td>\n","      <td>-0.023784</td>\n","      <td>-0.042627</td>\n","      <td>0.129051</td>\n","      <td>0.415437</td>\n","      <td>0.092375</td>\n","      <td>0.029581</td>\n","      <td>-0.014867</td>\n","      <td>-0.028881</td>\n","      <td>-0.042388</td>\n","      <td>-0.009877</td>\n","      <td>0.007138</td>\n","      <td>0.215218</td>\n","      <td>-0.304339</td>\n","      <td>0.284749</td>\n","      <td>-0.046607</td>\n","      <td>0.047721</td>\n","      <td>-0.320104</td>\n","      <td>0.324702</td>\n","      <td>-0.293449</td>\n","      <td>-0.172731</td>\n","      <td>0.244220</td>\n","      <td>-0.040395</td>\n","      <td>0.011228</td>\n","      <td>0.004389</td>\n","      <td>-0.020348</td>\n","      <td>-0.024065</td>\n","      <td>0.176421</td>\n","      <td>0.075400</td>\n","      <td>0.185248</td>\n","      <td>-0.072021</td>\n","      <td>-0.220747</td>\n","      <td>0.057374</td>\n","      <td>0.240672</td>\n","      <td>-0.022118</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Carroll</td>\n","      <td>[remarkable, Alice, think, way, hear, Rabbit, ...</td>\n","      <td>0.078226</td>\n","      <td>-0.231144</td>\n","      <td>0.424738</td>\n","      <td>0.433419</td>\n","      <td>-0.135063</td>\n","      <td>-0.150943</td>\n","      <td>-0.315627</td>\n","      <td>0.444615</td>\n","      <td>0.319292</td>\n","      <td>0.713312</td>\n","      <td>-0.050013</td>\n","      <td>0.037581</td>\n","      <td>-0.324206</td>\n","      <td>0.491446</td>\n","      <td>-0.023936</td>\n","      <td>0.312761</td>\n","      <td>0.155090</td>\n","      <td>-0.117786</td>\n","      <td>0.102776</td>\n","      <td>-0.179020</td>\n","      <td>-0.018815</td>\n","      <td>0.009269</td>\n","      <td>-0.236493</td>\n","      <td>0.201043</td>\n","      <td>0.279777</td>\n","      <td>0.098908</td>\n","      <td>-0.387835</td>\n","      <td>-0.019561</td>\n","      <td>-0.054540</td>\n","      <td>0.231978</td>\n","      <td>-0.018572</td>\n","      <td>-0.066042</td>\n","      <td>-0.001379</td>\n","      <td>-0.194701</td>\n","      <td>0.290980</td>\n","      <td>0.088063</td>\n","      <td>-0.241620</td>\n","      <td>-0.109820</td>\n","      <td>...</td>\n","      <td>-0.322329</td>\n","      <td>0.209217</td>\n","      <td>-0.363493</td>\n","      <td>-0.393473</td>\n","      <td>-0.242276</td>\n","      <td>-0.142030</td>\n","      <td>-0.021504</td>\n","      <td>-0.061740</td>\n","      <td>0.188295</td>\n","      <td>0.623350</td>\n","      <td>0.140418</td>\n","      <td>0.063806</td>\n","      <td>-0.007322</td>\n","      <td>-0.039991</td>\n","      <td>-0.055212</td>\n","      <td>-0.035048</td>\n","      <td>-0.004581</td>\n","      <td>0.331123</td>\n","      <td>-0.459101</td>\n","      <td>0.455266</td>\n","      <td>-0.081682</td>\n","      <td>0.079585</td>\n","      <td>-0.511063</td>\n","      <td>0.523700</td>\n","      <td>-0.461552</td>\n","      <td>-0.267420</td>\n","      <td>0.344113</td>\n","      <td>-0.031608</td>\n","      <td>0.013197</td>\n","      <td>0.011332</td>\n","      <td>-0.039577</td>\n","      <td>-0.043046</td>\n","      <td>0.253098</td>\n","      <td>0.117555</td>\n","      <td>0.279501</td>\n","      <td>-0.123866</td>\n","      <td>-0.309077</td>\n","      <td>0.090107</td>\n","      <td>0.354641</td>\n","      <td>-0.013576</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Carroll</td>\n","      <td>[oh, dear]</td>\n","      <td>0.067305</td>\n","      <td>-0.172221</td>\n","      <td>0.356054</td>\n","      <td>0.341043</td>\n","      <td>-0.101557</td>\n","      <td>-0.132718</td>\n","      <td>-0.223570</td>\n","      <td>0.349203</td>\n","      <td>0.244916</td>\n","      <td>0.528414</td>\n","      <td>-0.036462</td>\n","      <td>0.024717</td>\n","      <td>-0.267669</td>\n","      <td>0.374389</td>\n","      <td>0.007332</td>\n","      <td>0.238810</td>\n","      <td>0.118314</td>\n","      <td>-0.097823</td>\n","      <td>0.075837</td>\n","      <td>-0.157954</td>\n","      <td>-0.031368</td>\n","      <td>0.021877</td>\n","      <td>-0.189552</td>\n","      <td>0.153848</td>\n","      <td>0.248424</td>\n","      <td>0.086758</td>\n","      <td>-0.301894</td>\n","      <td>-0.007183</td>\n","      <td>-0.033442</td>\n","      <td>0.185841</td>\n","      <td>-0.004225</td>\n","      <td>-0.042440</td>\n","      <td>-0.009377</td>\n","      <td>-0.154178</td>\n","      <td>0.220290</td>\n","      <td>0.056979</td>\n","      <td>-0.187647</td>\n","      <td>-0.080040</td>\n","      <td>...</td>\n","      <td>-0.257840</td>\n","      <td>0.157914</td>\n","      <td>-0.272796</td>\n","      <td>-0.306883</td>\n","      <td>-0.181569</td>\n","      <td>-0.099395</td>\n","      <td>-0.009606</td>\n","      <td>-0.036041</td>\n","      <td>0.137915</td>\n","      <td>0.495135</td>\n","      <td>0.108748</td>\n","      <td>0.037299</td>\n","      <td>0.001662</td>\n","      <td>-0.036174</td>\n","      <td>-0.042440</td>\n","      <td>-0.032943</td>\n","      <td>-0.000778</td>\n","      <td>0.263550</td>\n","      <td>-0.365208</td>\n","      <td>0.344609</td>\n","      <td>-0.045369</td>\n","      <td>0.053893</td>\n","      <td>-0.382657</td>\n","      <td>0.415819</td>\n","      <td>-0.371559</td>\n","      <td>-0.199985</td>\n","      <td>0.268662</td>\n","      <td>-0.009539</td>\n","      <td>-0.001680</td>\n","      <td>0.013214</td>\n","      <td>-0.036683</td>\n","      <td>-0.021286</td>\n","      <td>0.176651</td>\n","      <td>0.073824</td>\n","      <td>0.218180</td>\n","      <td>-0.092009</td>\n","      <td>-0.255284</td>\n","      <td>0.078553</td>\n","      <td>0.273098</td>\n","      <td>-0.012460</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Carroll</td>\n","      <td>[shall, late]</td>\n","      <td>0.036554</td>\n","      <td>-0.128396</td>\n","      <td>0.243184</td>\n","      <td>0.249459</td>\n","      <td>-0.071475</td>\n","      <td>-0.083279</td>\n","      <td>-0.182885</td>\n","      <td>0.260272</td>\n","      <td>0.177184</td>\n","      <td>0.413054</td>\n","      <td>-0.038989</td>\n","      <td>0.010480</td>\n","      <td>-0.182981</td>\n","      <td>0.290358</td>\n","      <td>-0.010850</td>\n","      <td>0.181951</td>\n","      <td>0.096650</td>\n","      <td>-0.061323</td>\n","      <td>0.054553</td>\n","      <td>-0.106745</td>\n","      <td>-0.020145</td>\n","      <td>0.004751</td>\n","      <td>-0.141043</td>\n","      <td>0.118108</td>\n","      <td>0.170017</td>\n","      <td>0.062201</td>\n","      <td>-0.235599</td>\n","      <td>-0.015271</td>\n","      <td>-0.029049</td>\n","      <td>0.124873</td>\n","      <td>-0.005625</td>\n","      <td>-0.039979</td>\n","      <td>0.000178</td>\n","      <td>-0.108175</td>\n","      <td>0.164856</td>\n","      <td>0.059768</td>\n","      <td>-0.139928</td>\n","      <td>-0.062678</td>\n","      <td>...</td>\n","      <td>-0.183925</td>\n","      <td>0.118869</td>\n","      <td>-0.210392</td>\n","      <td>-0.224830</td>\n","      <td>-0.138410</td>\n","      <td>-0.085344</td>\n","      <td>-0.014477</td>\n","      <td>-0.037121</td>\n","      <td>0.117700</td>\n","      <td>0.352185</td>\n","      <td>0.081440</td>\n","      <td>0.024811</td>\n","      <td>-0.011285</td>\n","      <td>-0.026287</td>\n","      <td>-0.030095</td>\n","      <td>-0.014947</td>\n","      <td>0.000544</td>\n","      <td>0.190926</td>\n","      <td>-0.262653</td>\n","      <td>0.259266</td>\n","      <td>-0.035862</td>\n","      <td>0.042064</td>\n","      <td>-0.287016</td>\n","      <td>0.291218</td>\n","      <td>-0.259948</td>\n","      <td>-0.152244</td>\n","      <td>0.204379</td>\n","      <td>-0.030089</td>\n","      <td>0.003313</td>\n","      <td>0.009476</td>\n","      <td>-0.017117</td>\n","      <td>-0.022798</td>\n","      <td>0.145846</td>\n","      <td>0.068606</td>\n","      <td>0.159695</td>\n","      <td>-0.061070</td>\n","      <td>-0.189000</td>\n","      <td>0.044729</td>\n","      <td>0.207115</td>\n","      <td>-0.008538</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 102 columns</p>\n","</div>"],"text/plain":["    author  ...        99\n","0  Carroll  ... -0.019668\n","1  Carroll  ... -0.022118\n","2  Carroll  ... -0.013576\n","3  Carroll  ... -0.012460\n","4  Carroll  ... -0.008538\n","\n","[5 rows x 102 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"C07ifrFzzrHd"},"source":["# Modeling"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CldJrYtLzGzm","executionInfo":{"status":"ok","timestamp":1613697281713,"user_tz":360,"elapsed":12583,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"fecfe786-0842-4962-b3c7-df876ed1b2b4"},"source":["from sklearn.linear_model import LogisticRegression\r\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","Y = sentences['author']\r\n","X = np.array(sentences.drop(['text','author'], 1))\r\n","\r\n","# Split the dataset into training and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\r\n","\r\n","# Models\r\n","lr = LogisticRegression()\r\n","rfc = RandomForestClassifier()\r\n","gbc = GradientBoostingClassifier()\r\n","\r\n","lr.fit(X_train, y_train)\r\n","rfc.fit(X_train, y_train)\r\n","gbc.fit(X_train, y_train)\r\n","\r\n","print(\"----------------------Logistic Regression Scores----------------------\")\r\n","print('Training set score:', lr.score(X_train, y_train))\r\n","print('\\nTest set score:', lr.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Random Forest Scores----------------------\")\r\n","print('Training set score:', rfc.score(X_train, y_train))\r\n","print('\\nTest set score:', rfc.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Gradient Boosting Scores----------------------\")\r\n","print('Training set score:', gbc.score(X_train, y_train))\r\n","print('\\nTest set score:', gbc.score(X_test, y_test))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["----------------------Logistic Regression Scores----------------------\n","Training set score: 0.7197231833910035\n","\n","Test set score: 0.7101167315175098\n","----------------------Random Forest Scores----------------------\n","Training set score: 0.9913494809688581\n","\n","Test set score: 0.72568093385214\n","----------------------Gradient Boosting Scores----------------------\n","Training set score: 0.8784602076124568\n","\n","Test set score: 0.7237354085603113\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2NIdUvcEzPe2","executionInfo":{"status":"ok","timestamp":1613697421367,"user_tz":360,"elapsed":152230,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Load Google's pretrained word2vec model.\r\n","model_pretrained = gensim.models.KeyedVectors.load_word2vec_format(\r\n","    'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"xEs3oQhPzV37","executionInfo":{"status":"ok","timestamp":1613697421582,"user_tz":360,"elapsed":152438,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"f2b23552-dd15-481f-fc54-458942bc8804"},"source":["word2vec_arr = np.zeros((sentences.shape[0],300))\r\n","\r\n","for i, sentence in enumerate(sentences[\"text\"]):\r\n","  try:\r\n","    word2vec_arr[i,:] = np.mean([model_pretrained[lemma] for lemma in sentence], axis=0)\r\n","  except KeyError:\r\n","    word2vec_arr[i,:] = np.full((1,300), np.nan)\r\n","    continue\r\n","\r\n","word2vec_arr = pd.DataFrame(word2vec_arr)\r\n","sentences = pd.concat([sentences[[\"author\", \"text\"]],word2vec_arr], axis=1)\r\n","sentences.dropna(inplace=True)\r\n","\r\n","print(\"Shape of the dataset: {}\".format(sentences.shape))\r\n","sentences.head()"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Shape of the dataset: (2883, 302)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>text</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>...</th>\n","      <th>260</th>\n","      <th>261</th>\n","      <th>262</th>\n","      <th>263</th>\n","      <th>264</th>\n","      <th>265</th>\n","      <th>266</th>\n","      <th>267</th>\n","      <th>268</th>\n","      <th>269</th>\n","      <th>270</th>\n","      <th>271</th>\n","      <th>272</th>\n","      <th>273</th>\n","      <th>274</th>\n","      <th>275</th>\n","      <th>276</th>\n","      <th>277</th>\n","      <th>278</th>\n","      <th>279</th>\n","      <th>280</th>\n","      <th>281</th>\n","      <th>282</th>\n","      <th>283</th>\n","      <th>284</th>\n","      <th>285</th>\n","      <th>286</th>\n","      <th>287</th>\n","      <th>288</th>\n","      <th>289</th>\n","      <th>290</th>\n","      <th>291</th>\n","      <th>292</th>\n","      <th>293</th>\n","      <th>294</th>\n","      <th>295</th>\n","      <th>296</th>\n","      <th>297</th>\n","      <th>298</th>\n","      <th>299</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Carroll</td>\n","      <td>[Alice, begin, tired, sit, sister, bank, have,...</td>\n","      <td>0.046265</td>\n","      <td>0.016199</td>\n","      <td>-0.036288</td>\n","      <td>0.082410</td>\n","      <td>-0.010284</td>\n","      <td>0.015515</td>\n","      <td>0.005437</td>\n","      <td>-0.035947</td>\n","      <td>0.067871</td>\n","      <td>0.040186</td>\n","      <td>0.002303</td>\n","      <td>-0.071809</td>\n","      <td>-0.002277</td>\n","      <td>0.035602</td>\n","      <td>-0.087659</td>\n","      <td>0.067581</td>\n","      <td>0.083479</td>\n","      <td>0.109125</td>\n","      <td>0.038206</td>\n","      <td>-0.112296</td>\n","      <td>0.021118</td>\n","      <td>0.067197</td>\n","      <td>0.000285</td>\n","      <td>-0.046423</td>\n","      <td>0.030869</td>\n","      <td>0.000274</td>\n","      <td>-0.084494</td>\n","      <td>0.078152</td>\n","      <td>0.047164</td>\n","      <td>-0.023407</td>\n","      <td>-0.105367</td>\n","      <td>-0.039990</td>\n","      <td>-0.110767</td>\n","      <td>-0.065475</td>\n","      <td>0.023956</td>\n","      <td>0.010934</td>\n","      <td>0.094955</td>\n","      <td>0.015027</td>\n","      <td>...</td>\n","      <td>-0.055796</td>\n","      <td>0.055115</td>\n","      <td>-0.117415</td>\n","      <td>-0.030527</td>\n","      <td>-0.015355</td>\n","      <td>0.163165</td>\n","      <td>-0.034854</td>\n","      <td>0.015172</td>\n","      <td>-0.106117</td>\n","      <td>0.035062</td>\n","      <td>0.086723</td>\n","      <td>0.159433</td>\n","      <td>0.103741</td>\n","      <td>0.062915</td>\n","      <td>0.097021</td>\n","      <td>-0.047644</td>\n","      <td>-0.026648</td>\n","      <td>-0.071558</td>\n","      <td>0.018080</td>\n","      <td>-0.039431</td>\n","      <td>0.121521</td>\n","      <td>-0.125867</td>\n","      <td>0.006816</td>\n","      <td>0.029865</td>\n","      <td>0.046413</td>\n","      <td>0.018112</td>\n","      <td>-0.087307</td>\n","      <td>0.042181</td>\n","      <td>-0.015435</td>\n","      <td>0.128412</td>\n","      <td>-0.066516</td>\n","      <td>0.029852</td>\n","      <td>-0.042609</td>\n","      <td>-0.044208</td>\n","      <td>-0.056998</td>\n","      <td>-0.063269</td>\n","      <td>0.000244</td>\n","      <td>-0.085071</td>\n","      <td>-0.000340</td>\n","      <td>-0.064371</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Carroll</td>\n","      <td>[consider, mind, hot, day, feel, sleepy, stupi...</td>\n","      <td>0.046331</td>\n","      <td>0.020463</td>\n","      <td>-0.002012</td>\n","      <td>0.101565</td>\n","      <td>-0.066478</td>\n","      <td>-0.035698</td>\n","      <td>0.045293</td>\n","      <td>-0.068695</td>\n","      <td>0.044050</td>\n","      <td>0.079996</td>\n","      <td>0.010562</td>\n","      <td>-0.098240</td>\n","      <td>-0.024309</td>\n","      <td>0.042576</td>\n","      <td>-0.078658</td>\n","      <td>0.026042</td>\n","      <td>-0.025208</td>\n","      <td>0.128391</td>\n","      <td>0.054481</td>\n","      <td>-0.081564</td>\n","      <td>-0.022604</td>\n","      <td>0.060187</td>\n","      <td>0.014813</td>\n","      <td>-0.002640</td>\n","      <td>0.089216</td>\n","      <td>0.010905</td>\n","      <td>-0.080477</td>\n","      <td>0.078742</td>\n","      <td>0.071459</td>\n","      <td>-0.042953</td>\n","      <td>-0.011639</td>\n","      <td>0.026516</td>\n","      <td>-0.042924</td>\n","      <td>-0.028997</td>\n","      <td>-0.010134</td>\n","      <td>-0.033885</td>\n","      <td>0.051852</td>\n","      <td>0.018926</td>\n","      <td>...</td>\n","      <td>0.037855</td>\n","      <td>0.004276</td>\n","      <td>-0.073813</td>\n","      <td>0.033909</td>\n","      <td>0.053077</td>\n","      <td>0.063299</td>\n","      <td>-0.044852</td>\n","      <td>-0.004278</td>\n","      <td>-0.053132</td>\n","      <td>-0.035156</td>\n","      <td>0.047930</td>\n","      <td>0.126340</td>\n","      <td>0.125036</td>\n","      <td>0.046570</td>\n","      <td>0.049766</td>\n","      <td>-0.076279</td>\n","      <td>-0.069141</td>\n","      <td>-0.122912</td>\n","      <td>-0.052948</td>\n","      <td>0.055787</td>\n","      <td>0.081729</td>\n","      <td>0.011096</td>\n","      <td>0.005422</td>\n","      <td>0.050716</td>\n","      <td>-0.050148</td>\n","      <td>-0.008294</td>\n","      <td>-0.072707</td>\n","      <td>-0.002824</td>\n","      <td>0.021307</td>\n","      <td>0.035784</td>\n","      <td>0.055940</td>\n","      <td>0.085838</td>\n","      <td>-0.067052</td>\n","      <td>-0.013628</td>\n","      <td>-0.027802</td>\n","      <td>-0.033665</td>\n","      <td>-0.023586</td>\n","      <td>0.009620</td>\n","      <td>0.030316</td>\n","      <td>0.000908</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Carroll</td>\n","      <td>[remarkable, Alice, think, way, hear, Rabbit, ...</td>\n","      <td>0.061646</td>\n","      <td>-0.006958</td>\n","      <td>-0.013023</td>\n","      <td>0.147003</td>\n","      <td>-0.052933</td>\n","      <td>-0.077866</td>\n","      <td>0.033997</td>\n","      <td>-0.061890</td>\n","      <td>0.104706</td>\n","      <td>0.151611</td>\n","      <td>-0.083191</td>\n","      <td>-0.102318</td>\n","      <td>-0.043243</td>\n","      <td>-0.060654</td>\n","      <td>-0.060211</td>\n","      <td>0.105164</td>\n","      <td>0.127869</td>\n","      <td>0.207825</td>\n","      <td>-0.009186</td>\n","      <td>0.009155</td>\n","      <td>0.005402</td>\n","      <td>0.077332</td>\n","      <td>0.129974</td>\n","      <td>-0.026632</td>\n","      <td>0.149017</td>\n","      <td>0.043540</td>\n","      <td>-0.082504</td>\n","      <td>0.020443</td>\n","      <td>0.117149</td>\n","      <td>-0.014988</td>\n","      <td>-0.064789</td>\n","      <td>-0.023331</td>\n","      <td>-0.068970</td>\n","      <td>0.002205</td>\n","      <td>0.015739</td>\n","      <td>0.018581</td>\n","      <td>0.110168</td>\n","      <td>0.057068</td>\n","      <td>...</td>\n","      <td>-0.073837</td>\n","      <td>-0.021027</td>\n","      <td>0.002594</td>\n","      <td>0.025757</td>\n","      <td>-0.004457</td>\n","      <td>0.067825</td>\n","      <td>-0.060242</td>\n","      <td>-0.063232</td>\n","      <td>-0.079094</td>\n","      <td>0.098316</td>\n","      <td>0.021147</td>\n","      <td>0.124046</td>\n","      <td>0.078278</td>\n","      <td>0.056248</td>\n","      <td>0.099792</td>\n","      <td>-0.106703</td>\n","      <td>0.034882</td>\n","      <td>-0.111328</td>\n","      <td>-0.009624</td>\n","      <td>-0.011642</td>\n","      <td>0.088547</td>\n","      <td>-0.059265</td>\n","      <td>-0.041046</td>\n","      <td>0.069794</td>\n","      <td>-0.002939</td>\n","      <td>0.018978</td>\n","      <td>-0.025116</td>\n","      <td>-0.057938</td>\n","      <td>0.007706</td>\n","      <td>0.120476</td>\n","      <td>-0.006882</td>\n","      <td>0.030754</td>\n","      <td>-0.073837</td>\n","      <td>-0.010359</td>\n","      <td>-0.086411</td>\n","      <td>-0.156464</td>\n","      <td>-0.000771</td>\n","      <td>-0.000549</td>\n","      <td>-0.003784</td>\n","      <td>0.029114</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Carroll</td>\n","      <td>[oh, dear]</td>\n","      <td>0.073975</td>\n","      <td>0.134277</td>\n","      <td>0.141357</td>\n","      <td>0.256348</td>\n","      <td>-0.147949</td>\n","      <td>0.099670</td>\n","      <td>0.077148</td>\n","      <td>-0.093628</td>\n","      <td>0.108887</td>\n","      <td>0.281738</td>\n","      <td>-0.201172</td>\n","      <td>-0.020752</td>\n","      <td>-0.266602</td>\n","      <td>0.000732</td>\n","      <td>-0.036865</td>\n","      <td>0.294434</td>\n","      <td>0.158203</td>\n","      <td>0.287109</td>\n","      <td>-0.114624</td>\n","      <td>0.038330</td>\n","      <td>0.141357</td>\n","      <td>-0.046021</td>\n","      <td>0.407227</td>\n","      <td>0.047852</td>\n","      <td>0.322266</td>\n","      <td>0.213379</td>\n","      <td>-0.090576</td>\n","      <td>0.022812</td>\n","      <td>0.171265</td>\n","      <td>-0.283203</td>\n","      <td>0.193848</td>\n","      <td>0.092285</td>\n","      <td>-0.122803</td>\n","      <td>0.029770</td>\n","      <td>-0.116943</td>\n","      <td>0.026123</td>\n","      <td>0.137451</td>\n","      <td>0.055298</td>\n","      <td>...</td>\n","      <td>-0.014648</td>\n","      <td>0.112793</td>\n","      <td>0.071716</td>\n","      <td>-0.133911</td>\n","      <td>-0.091553</td>\n","      <td>-0.079041</td>\n","      <td>-0.156250</td>\n","      <td>-0.029053</td>\n","      <td>-0.024719</td>\n","      <td>0.102844</td>\n","      <td>-0.084473</td>\n","      <td>0.163086</td>\n","      <td>-0.031738</td>\n","      <td>-0.084473</td>\n","      <td>0.149170</td>\n","      <td>-0.082031</td>\n","      <td>-0.023438</td>\n","      <td>-0.199219</td>\n","      <td>-0.253418</td>\n","      <td>0.206055</td>\n","      <td>0.160156</td>\n","      <td>-0.056030</td>\n","      <td>-0.138184</td>\n","      <td>0.208496</td>\n","      <td>0.030762</td>\n","      <td>0.033447</td>\n","      <td>-0.061890</td>\n","      <td>-0.022461</td>\n","      <td>-0.146240</td>\n","      <td>-0.032959</td>\n","      <td>0.058228</td>\n","      <td>0.000854</td>\n","      <td>-0.094971</td>\n","      <td>-0.052668</td>\n","      <td>-0.091919</td>\n","      <td>-0.142456</td>\n","      <td>-0.053711</td>\n","      <td>-0.112671</td>\n","      <td>-0.148193</td>\n","      <td>0.186798</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Carroll</td>\n","      <td>[shall, late]</td>\n","      <td>0.095215</td>\n","      <td>0.084473</td>\n","      <td>0.206787</td>\n","      <td>0.211182</td>\n","      <td>0.043579</td>\n","      <td>-0.155762</td>\n","      <td>0.088379</td>\n","      <td>-0.038574</td>\n","      <td>0.065613</td>\n","      <td>0.001221</td>\n","      <td>-0.144287</td>\n","      <td>0.001465</td>\n","      <td>-0.000771</td>\n","      <td>0.189453</td>\n","      <td>-0.058350</td>\n","      <td>-0.062134</td>\n","      <td>0.045898</td>\n","      <td>0.130127</td>\n","      <td>0.211426</td>\n","      <td>0.074341</td>\n","      <td>-0.056122</td>\n","      <td>-0.111145</td>\n","      <td>0.104355</td>\n","      <td>0.069946</td>\n","      <td>0.191895</td>\n","      <td>0.057404</td>\n","      <td>-0.003906</td>\n","      <td>0.107666</td>\n","      <td>-0.040039</td>\n","      <td>0.082275</td>\n","      <td>-0.046707</td>\n","      <td>-0.150635</td>\n","      <td>-0.006226</td>\n","      <td>0.048950</td>\n","      <td>-0.088745</td>\n","      <td>0.088501</td>\n","      <td>-0.081573</td>\n","      <td>-0.180542</td>\n","      <td>...</td>\n","      <td>0.133301</td>\n","      <td>0.074219</td>\n","      <td>0.049438</td>\n","      <td>0.092743</td>\n","      <td>0.077618</td>\n","      <td>0.084229</td>\n","      <td>-0.100586</td>\n","      <td>-0.022217</td>\n","      <td>0.043579</td>\n","      <td>-0.029785</td>\n","      <td>0.212158</td>\n","      <td>0.073242</td>\n","      <td>0.100220</td>\n","      <td>0.062256</td>\n","      <td>0.167480</td>\n","      <td>0.010693</td>\n","      <td>-0.139923</td>\n","      <td>-0.013805</td>\n","      <td>-0.127014</td>\n","      <td>0.001465</td>\n","      <td>-0.120972</td>\n","      <td>0.063080</td>\n","      <td>-0.024597</td>\n","      <td>0.027847</td>\n","      <td>0.010254</td>\n","      <td>-0.073547</td>\n","      <td>0.100098</td>\n","      <td>0.023438</td>\n","      <td>0.107178</td>\n","      <td>0.065918</td>\n","      <td>-0.021667</td>\n","      <td>-0.103516</td>\n","      <td>-0.038578</td>\n","      <td>-0.007385</td>\n","      <td>0.020264</td>\n","      <td>0.134155</td>\n","      <td>-0.177246</td>\n","      <td>-0.254639</td>\n","      <td>-0.212158</td>\n","      <td>0.087646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 302 columns</p>\n","</div>"],"text/plain":["    author  ...       299\n","0  Carroll  ... -0.064371\n","1  Carroll  ...  0.000908\n","2  Carroll  ...  0.029114\n","3  Carroll  ...  0.186798\n","4  Carroll  ...  0.087646\n","\n","[5 rows x 302 columns]"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3EAYDq7zaLO","executionInfo":{"status":"ok","timestamp":1613697445491,"user_tz":360,"elapsed":176340,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"76345522-46c4-4671-a2d6-83f5b5cc1259"},"source":["from sklearn.linear_model import LogisticRegression\r\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","Y = sentences['author']\r\n","X = np.array(sentences.drop(['text','author'], 1))\r\n","\r\n","# Split the dataset into training and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\r\n","\r\n","# Models\r\n","lr = LogisticRegression()\r\n","rfc = RandomForestClassifier()\r\n","gbc = GradientBoostingClassifier()\r\n","\r\n","lr.fit(X_train, y_train)\r\n","rfc.fit(X_train, y_train)\r\n","gbc.fit(X_train, y_train)\r\n","\r\n","print(\"----------------------Logistic Regression Scores----------------------\")\r\n","print('Training set score:', lr.score(X_train, y_train))\r\n","print('\\nTest set score:', lr.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Random Forest Scores----------------------\")\r\n","print('Training set score:', rfc.score(X_train, y_train))\r\n","print('\\nTest set score:', rfc.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Gradient Boosting Scores----------------------\")\r\n","print('Training set score:', gbc.score(X_train, y_train))\r\n","print('\\nTest set score:', gbc.score(X_test, y_test))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["----------------------Logistic Regression Scores----------------------\n","Training set score: 0.8617698091382302\n","\n","Test set score: 0.8110918544194108\n","----------------------Random Forest Scores----------------------\n","Training set score: 0.9930595720069404\n","\n","Test set score: 0.7686308492201039\n","----------------------Gradient Boosting Scores----------------------\n","Training set score: 0.9710815500289185\n","\n","Test set score: 0.7651646447140381\n"],"name":"stdout"}]}]}