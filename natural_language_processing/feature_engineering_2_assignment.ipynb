{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"feature_engineering_2_assignment.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-EeXt3e_hEP","executionInfo":{"status":"ok","timestamp":1613675029131,"user_tz":360,"elapsed":4210,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"c026384e-bbe1-4776-8e30-3a2f228d8391"},"source":["import numpy as np\r\n","import pandas as pd\r\n","import sklearn\r\n","import spacy\r\n","import re\r\n","from nltk.corpus import gutenberg\r\n","import nltk\r\n","import warnings\r\n","warnings.filterwarnings(\"ignore\")\r\n","from nltk import sent_tokenize, word_tokenize\r\n","nltk.download('punkt')\r\n","\r\n","nltk.download('gutenberg')\r\n","!python -m spacy download en"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KAFY4yObDuFR","executionInfo":{"status":"ok","timestamp":1613675029135,"user_tz":360,"elapsed":4211,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Utility function for standard text cleaning\r\n","def text_cleaner(text):\r\n","    # Visual inspection identifies a form of punctuation that spaCy doesn't\r\n","    # recognize: the double dash --. Better get rid of it now!\r\n","    text = re.sub(r'--',' ',text)\r\n","    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\r\n","    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\r\n","    text = ' '.join(text.split())\r\n","    return text"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWAuq5kyP-C1","executionInfo":{"status":"ok","timestamp":1613675029136,"user_tz":360,"elapsed":4209,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Load and clean the data\r\n","persuasion = gutenberg.raw('austen-persuasion.txt')\r\n","alice = gutenberg.raw('carroll-alice.txt')\r\n","\r\n","# The chapter indicator is idiosyncratic\r\n","persuasion = re.sub(r'Chapter \\d+', '', persuasion)\r\n","alice = re.sub(r'CHAPTER .*', '', alice)\r\n","    \r\n","alice = text_cleaner(alice)\r\n","persuasion = text_cleaner(persuasion)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4iEqS0XQAO4","executionInfo":{"status":"ok","timestamp":1613675049450,"user_tz":360,"elapsed":24522,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Parse the cleaned novels. This can take some time.\r\n","nlp = spacy.load('en')\r\n","alice_doc = nlp(alice)\r\n","persuasion_doc = nlp(persuasion)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"zbMZZphyQUgv","executionInfo":{"status":"ok","timestamp":1613675049477,"user_tz":360,"elapsed":24540,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"96009e61-29d6-4eeb-aa69-375248c99ee3"},"source":["# Group into sentences\r\n","alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\r\n","persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\r\n","\r\n","# Combine the sentences from the two novels into one DataFrame\r\n","sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\r\n","sentences.head()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(So, she, was, considering, in, her, own, mind...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(Oh, dear, !)</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(I, shall, be, late, !, ')</td>\n","      <td>Carroll</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text   author\n","0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n","1  (So, she, was, considering, in, her, own, mind...  Carroll\n","2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n","3                                      (Oh, dear, !)  Carroll\n","4                         (I, shall, be, late, !, ')  Carroll"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"cph0DnDwQYnZ","executionInfo":{"status":"ok","timestamp":1613675050117,"user_tz":360,"elapsed":25176,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["# Get rid of stop words and punctuation,\r\n","# and lemmatize the tokens\r\n","for i, sentence in enumerate(sentences[\"text\"]):\r\n","    sentences.loc[i, \"text\"] = \" \".join(\r\n","        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":474},"id":"X7j3reVMQcsU","executionInfo":{"status":"ok","timestamp":1613675050577,"user_tz":360,"elapsed":25625,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"6fdeb896-03da-4fec-d5a7-dbe138452601"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\r\n","\r\n","vectorizer = TfidfVectorizer(\r\n","    max_df=0.5, min_df=2, use_idf=True, norm=u'l2', smooth_idf=True)\r\n","\r\n","\r\n","# Applying the vectorizer\r\n","X = vectorizer.fit_transform(sentences[\"text\"])\r\n","\r\n","tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n","sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\r\n","\r\n","# Keep in mind that log base 2 of 1 is 0,\r\n","# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n","sentences.head()"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>abide</th>\n","      <th>ability</th>\n","      <th>able</th>\n","      <th>abominate</th>\n","      <th>abroad</th>\n","      <th>absence</th>\n","      <th>absent</th>\n","      <th>absolute</th>\n","      <th>absolutely</th>\n","      <th>absurd</th>\n","      <th>abuse</th>\n","      <th>accept</th>\n","      <th>acceptable</th>\n","      <th>acceptance</th>\n","      <th>accession</th>\n","      <th>accident</th>\n","      <th>accidentally</th>\n","      <th>accommodate</th>\n","      <th>accommodation</th>\n","      <th>accompany</th>\n","      <th>accomplish</th>\n","      <th>accomplishment</th>\n","      <th>accord</th>\n","      <th>accordingly</th>\n","      <th>account</th>\n","      <th>accuse</th>\n","      <th>acknowledge</th>\n","      <th>acknowledgement</th>\n","      <th>acquaint</th>\n","      <th>acquaintance</th>\n","      <th>acquainted</th>\n","      <th>acquiescence</th>\n","      <th>acquire</th>\n","      <th>acre</th>\n","      <th>act</th>\n","      <th>action</th>\n","      <th>active</th>\n","      <th>activity</th>\n","      <th>actual</th>\n","      <th>actually</th>\n","      <th>...</th>\n","      <th>wishing</th>\n","      <th>wit</th>\n","      <th>withdraw</th>\n","      <th>withstand</th>\n","      <th>witness</th>\n","      <th>woman</th>\n","      <th>wonder</th>\n","      <th>wonderful</th>\n","      <th>wonderland</th>\n","      <th>wood</th>\n","      <th>word</th>\n","      <th>work</th>\n","      <th>world</th>\n","      <th>worldly</th>\n","      <th>worth</th>\n","      <th>worthy</th>\n","      <th>wound</th>\n","      <th>wow</th>\n","      <th>wretched</th>\n","      <th>wretchedness</th>\n","      <th>wriggle</th>\n","      <th>write</th>\n","      <th>writing</th>\n","      <th>wrong</th>\n","      <th>wrought</th>\n","      <th>yard</th>\n","      <th>yarmouth</th>\n","      <th>yawn</th>\n","      <th>ye</th>\n","      <th>year</th>\n","      <th>yer</th>\n","      <th>yes</th>\n","      <th>yesterday</th>\n","      <th>yield</th>\n","      <th>young</th>\n","      <th>youth</th>\n","      <th>zeal</th>\n","      <th>zealous</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Alice begin tired sit sister bank have twice p...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.224454</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>consider mind hot day feel sleepy stupid pleas...</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>remarkable Alice think way hear Rabbit oh dear</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>oh dear</td>\n","      <td>Carroll</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>shall late</td>\n","      <td>Carroll</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2867 columns</p>\n","</div>"],"text/plain":["   abide  ability  ...                                               text   author\n","0    0.0      0.0  ...  Alice begin tired sit sister bank have twice p...  Carroll\n","1    0.0      0.0  ...  consider mind hot day feel sleepy stupid pleas...  Carroll\n","2    0.0      0.0  ...     remarkable Alice think way hear Rabbit oh dear  Carroll\n","3    0.0      0.0  ...                                            oh dear  Carroll\n","4    0.0      0.0  ...                                         shall late  Carroll\n","\n","[5 rows x 2867 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"jkATvJ1zQleP","executionInfo":{"status":"error","timestamp":1613675059125,"user_tz":360,"elapsed":34166,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"b6e19972-b2dd-4eb8-81b4-176cdac37aeb"},"source":["from sklearn.linear_model import LogisticRegression\r\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","Y = sentences['author']\r\n","X = np.array(sentences.drop(['text','author'], 1))\r\n","\r\n","# Split the dataset into train and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\r\n","\r\n","# Models\r\n","lr = LogisticRegression()\r\n","rfc = RandomForestClassifier()\r\n","gbc = GradientBoostingClassifier()\r\n","\r\n","lr.fit(X_train, y_train)\r\n","rfc.fit(X_train, y_train)\r\n","gbc.fit(X_train, y_train)\r\n","\r\n","print(\"----------------------Logistic Regression Scores----------------------\")\r\n","print('Training set score:', lr.score(X_train, y_train))\r\n","print('\\nTest set score:', lr.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Random Forest Scores----------------------\")\r\n","print('Training set score:', rfc.score(X_train, y_train))\r\n","print('\\nTest set score:', rfc.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Gradient Boosting Scores----------------------\")\r\n","print('Training set score:', gbc.score(X_train, y_train))\r\n","print('\\nTest set score:', gbc.score(X_test, y_test))"],"execution_count":46,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-69020a612666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"M67RPCTXqxne"},"source":["---\r\n","2. In the 2-grams example above, you only used 2-grams as your features. This time, use both 1-grams and 2-grams together as your feature set. Run the same models as in the example and compare the results."]},{"cell_type":"code","metadata":{"id":"i1akZqeQQpbt","executionInfo":{"status":"aborted","timestamp":1613675059114,"user_tz":360,"elapsed":34147,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["vectorizer = TfidfVectorizer(\r\n","    max_df=0.5, min_df=2, use_idf=True, norm=u'l2', smooth_idf=True, ngram_range=(1,2))\r\n","\r\n","\r\n","# Applying the vectorizer\r\n","X = vectorizer.fit_transform(sentences[\"text\"])\r\n","\r\n","tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n","sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\r\n","\r\n","# Keep in mind that log base 2 of 1 is 0,\r\n","# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n","sentences.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7Wx2FCpQr12","executionInfo":{"status":"aborted","timestamp":1613675059118,"user_tz":360,"elapsed":34142,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}}},"source":["Y = sentences['author']\r\n","X = np.array(sentences.drop(['text','author'], 1))\r\n","\r\n","# Split the dataset into training and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\r\n","\r\n","# Models\r\n","lr = LogisticRegression()\r\n","rfc = RandomForestClassifier()\r\n","gbc = GradientBoostingClassifier()\r\n","\r\n","lr.fit(X_train, y_train)\r\n","rfc.fit(X_train, y_train)\r\n","gbc.fit(X_train, y_train)\r\n","\r\n","print(\"----------------------Logistic Regression Scores----------------------\")\r\n","print('Training set score:', lr.score(X_train, y_train))\r\n","print('\\nTest set score:', lr.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Random Forest Scores----------------------\")\r\n","print('Training set score:', rfc.score(X_train, y_train))\r\n","print('\\nTest set score:', rfc.score(X_test, y_test))\r\n","\r\n","print(\"----------------------Gradient Boosting Scores----------------------\")\r\n","print('Training set score:', gbc.score(X_train, y_train))\r\n","print('\\nTest set score:', gbc.score(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w-lb-AswQ7mA"},"source":["---\r\n","1. Converting words or sentences into numeric vectors is fundamental when working with text data. To make sure that you have a solid handle on how these vectors work, generate the TF-IDF vectors for the last three sentences of the example from the beginning of this checkpoint (from the BoW revisited: TF-IDF section)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"chi9ts7KRG7Z","executionInfo":{"status":"ok","timestamp":1613675076195,"user_tz":360,"elapsed":407,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"b257b978-9ce5-4f53-84de-9d009ce47dea"},"source":["doc_string = r\"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"\r\n","doc = text_cleaner(doc_string)\r\n","doc"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\""]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPNyM-uiR1vj","executionInfo":{"status":"ok","timestamp":1613675078962,"user_tz":360,"elapsed":982,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"e52462bc-62d8-4e81-d5e8-75c633ed4b5f"},"source":["nlp = spacy.load('en_core_web_sm')\r\n","doc = nlp(doc)\r\n","doc"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing. I would rather put strawberries on my ice cream for dessert; they have the best taste. The taste of caramel is a fantastic accompaniment to tasty mint ice cream."]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U0ZT3SdDSJ38","executionInfo":{"status":"ok","timestamp":1613675080976,"user_tz":360,"elapsed":379,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"e1da1f48-6ed5-4e80-8c3b-3261c9c7c99a"},"source":["# Group into sentences\r\n","sents = [sent for sent in doc.sents]\r\n","sents\r\n","\r\n"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing.,\n"," I would rather put strawberries on my ice cream for dessert; they have the best taste.,\n"," The taste of caramel is a fantastic accompaniment to tasty mint ice cream.]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIgzWqU0g0hn","executionInfo":{"status":"ok","timestamp":1613675843593,"user_tz":360,"elapsed":293,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"5921c945-52df-4562-c642-6b49212181f8"},"source":["sentences = pd.Series(sents)\r\n","sentences"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    (The, Lumberjack, Song, is, the, funniest, Mon...\n","1    (I, would, rather, put, strawberries, on, my, ...\n","2    (The, taste, of, caramel, is, a, fantastic, ac...\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"4MUQh2T9hinI","executionInfo":{"status":"error","timestamp":1613675111495,"user_tz":360,"elapsed":388,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"76a09eba-720f-4ea0-dc53-0460e3370896"},"source":["# sentences[0].is_punct"],"execution_count":53,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-176009437338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'is_punct'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzvf9HU0jeAY","executionInfo":{"status":"ok","timestamp":1613675845427,"user_tz":360,"elapsed":290,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"7bb5b702-6765-4d85-ac75-3bd2d8b24829"},"source":["def clean_data(sentences):\r\n","    return \" \".join([token.lemma_ for token in sentences if not token.is_punct and not token.is_stop]).strip()\r\n","\r\n","sentences = sentences.apply(\r\n","    clean_data\r\n","    )\r\n","\r\n","sentences"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Lumberjack Song funniest Monty Python bit thin...\n","1              strawberry ice cream dessert good taste\n","2    taste caramel fantastic accompaniment tasty mi...\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfoSKXO6kipn","executionInfo":{"status":"ok","timestamp":1613675834868,"user_tz":360,"elapsed":354,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"ada0cc5b-bc6e-42c0-d1ef-9dfe4d065ab3"},"source":["for sent in sentences:\r\n","    print(sent)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Lumberjack Song funniest Monty Python bit think laugh\n","strawberry ice cream dessert good taste\n","taste caramel fantastic accompaniment tasty mint ice cream\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pm3eRdp5hDuK","executionInfo":{"status":"ok","timestamp":1613675394934,"user_tz":360,"elapsed":318,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"440769d4-3dc1-40e4-fc60-a722f0c94982"},"source":["# Get rid of stop words and punctuation,\r\n","# and lemmatize the tokens\r\n","for i in range(len(sentences)):\r\n","    sentences[i] = \" \".join([token.lemma_ for token in sentences[i] if not token.is_punct and not token.is_stop])\r\n","    \r\n","for sent in sentences:\r\n","    print(sent)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Lumberjack Song funniest Monty Python bit think laugh\n","strawberry ice cream dessert good taste\n","taste caramel fantastic accompaniment tasty mint ice cream\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"1dk9h1fwSOGf","executionInfo":{"status":"ok","timestamp":1613675402279,"user_tz":360,"elapsed":926,"user":{"displayName":"Taylor Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCE8G90wcGj0LyMdPz1s1HHFQGXUh414iGSqhD6Q=s64","userId":"07425549969609912014"}},"outputId":"608a0483-c5c0-429d-956d-c2f8622738ce"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\r\n","\r\n","vectorizer = TfidfVectorizer()\r\n","\r\n","\r\n","# Applying the vectorizer\r\n","X = vectorizer.fit_transform(sentences)\r\n","\r\n","tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\r\n","# display(tfidf_df)\r\n","sentences = pd.concat([tfidf_df, sentences], axis=1)\r\n","\r\n","# Keep in mind that log base 2 of 1 is 0,\r\n","# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\r\n","sentences.head()"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accompaniment</th>\n","      <th>bit</th>\n","      <th>caramel</th>\n","      <th>cream</th>\n","      <th>dessert</th>\n","      <th>fantastic</th>\n","      <th>funniest</th>\n","      <th>good</th>\n","      <th>ice</th>\n","      <th>laugh</th>\n","      <th>lumberjack</th>\n","      <th>mint</th>\n","      <th>monty</th>\n","      <th>python</th>\n","      <th>song</th>\n","      <th>strawberry</th>\n","      <th>taste</th>\n","      <th>tasty</th>\n","      <th>think</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.353553</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.353553</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.353553</td>\n","      <td>0.353553</td>\n","      <td>0.000000</td>\n","      <td>0.353553</td>\n","      <td>0.353553</td>\n","      <td>0.353553</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.353553</td>\n","      <td>Lumberjack Song funniest Monty Python bit thin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.349498</td>\n","      <td>0.459548</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.459548</td>\n","      <td>0.349498</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.459548</td>\n","      <td>0.349498</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>strawberry ice cream dessert good taste</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.385323</td>\n","      <td>0.000000</td>\n","      <td>0.385323</td>\n","      <td>0.293048</td>\n","      <td>0.000000</td>\n","      <td>0.385323</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.293048</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.385323</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.293048</td>\n","      <td>0.385323</td>\n","      <td>0.000000</td>\n","      <td>taste caramel fantastic accompaniment tasty mi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   accompaniment  ...                                                  0\n","0       0.000000  ...  Lumberjack Song funniest Monty Python bit thin...\n","1       0.000000  ...            strawberry ice cream dessert good taste\n","2       0.385323  ...  taste caramel fantastic accompaniment tasty mi...\n","\n","[3 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"XabKte2MFMT-"},"source":["4: 1.585, 1, 0, 1, 1.585, 0,0,0,0\r\n","\r\n","5: 0,0,0,0,0, .585, 1, 1.585, 1\r\n","\r\n","6: 0,0,0,0,0,0, 1, 0, 2"]}]}